============================================================
DISTILBERT CLASSIFIER
============================================================

CONFIGURATION
------------------------------------------------------------
Model: distilbert-base-uncased
Epochs: 3
Batch size: 8
Learning rate: 2e-05
Max length: 128
Validation: 5-fold Stratified Cross-Validation

RESULTS
------------------------------------------------------------
Macro F1:    0.2266 ± 0.0058
Weighted F1: 0.3507 ± 0.0229

PER-CLASS F1
------------------------------------------------------------
  Tamas (0): 0.6800
  Rajas (1): 0.0000
  Sattva (2): 0.0000

CONFUSION MATRIX
------------------------------------------------------------
              Pred_T  Pred_R  Pred_S
  Actual_T      51       0       0
  Actual_R      25       0       0
  Actual_S      23       0       0

CLASSIFICATION REPORT
------------------------------------------------------------
              precision    recall  f1-score   support

       Tamas       0.52      1.00      0.68        51
       Rajas       0.00      0.00      0.00        25
      Sattva       0.00      0.00      0.00        23

    accuracy                           0.52        99
   macro avg       0.17      0.33      0.23        99
weighted avg       0.27      0.52      0.35        99

============================================================
COMPARISON WITH BASELINE
============================================================
Baseline (TF-IDF + LogReg): Macro F1 = 0.3500 ± 0.0790
DistilBERT:                 Macro F1 = 0.2266 ± 0.0058
Difference:                 -0.1234
